{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suba\\.conda\\envs\\cpsc672\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import pickle\n",
    "\n",
    "from human import TerminalHuman\n",
    "from keyboard_agent import *\n",
    "from utils import *\n",
    "from LearnAtariReward import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIONS=4\n",
      "Press keys 1 2 3 ... to take actions 1 2 3 ...\n",
      "No keys pressed is taking action 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "demo_files = play(env, 5, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\suba\\Desktop\\CPSC 672\\miniRex2\\main.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/suba/Desktop/CPSC%20672/miniRex2/main.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m h\u001b[39m.\u001b[39;49minput(\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\suba\\Desktop\\CPSC 672\\miniRex2\\human.py:69\u001b[0m, in \u001b[0;36mTerminalHuman.input\u001b[1;34m(self, queries, on_real_robot)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minput\u001b[39m(\u001b[39mself\u001b[39m, queries, on_real_robot\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTo view a trajectory, press a number: [1,...,\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m]; when ready to select input \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39;49m(queries)))\n\u001b[0;32m     70\u001b[0m     inp \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     71\u001b[0m     \u001b[39mwhile\u001b[39;00m inp \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "h.input(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the demosntrations\n",
    "# output = play(env, 0, save=False)\n",
    "# res = play_rand(env, 15, 0, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ['1668105089.1177604',\n",
    " '1668105094.1521122',\n",
    " '1668105096.6714065',\n",
    " '1668105100.2791483',\n",
    " '1668105105.8747754',\n",
    " '1668105108.6929462',\n",
    " '1668105112.4706893',\n",
    " '1668105115.2749567',\n",
    " '1668105119.1750195',\n",
    " '1668105123.139814',\n",
    " '1668105125.4567327',\n",
    " '1668105128.4647155',\n",
    " '1668105131.5153224',\n",
    " '1668105135.0170794',\n",
    " '1668105138.4981039']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = 'data-rand/demonstrations/gym-'\n",
    "demonstrations = [pickle.load(open(demo_path+ f'{demo_name}' + '.pickle', 'rb'), encoding='latin1') for demo_name in res] # load from files\n",
    "# demos[demo #] = control, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted best to worst demos\n",
    "sorted_demonstrations = [(states, controls) for controls, states, reward in sorted(demonstrations, key=lambda pair: pair[2])]\n",
    "sorted_rewards = [reward for controls, states, reward in sorted(demonstrations, key=lambda pair: pair[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(demonstrations[i][0]) for i in range(len(demonstrations))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajs =  0\n",
    "num_snippets = 6000\n",
    "min_snippet_length =  min(np.min([len(d[0]) for d in sorted_demonstrations]), 30) #min length of trajectory for training comparison\n",
    "maximum_snippet_length = 100\n",
    "max_snippet_length = min(np.min([len(d[0]) for d in sorted_demonstrations]), maximum_snippet_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum traj length 31\n"
     ]
    }
   ],
   "source": [
    "# auto labelling, but this can be done with preference ranking\n",
    "training_obs, training_labels = create_training_data(sorted_demonstrations, num_trajs, num_snippets, min_snippet_length, max_snippet_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005\n",
    "weight_decay = 0.0\n",
    "num_iter = 20 #num times through training data\n",
    "l1_reg=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "99\n",
      "epoch 0 loss 1.641218662261963\n",
      "tensor(6.9289, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 0 loss 0.018973175436258316\n",
      "tensor(12.7387, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 0 loss 2.141167402267456\n",
      "tensor(10.4205, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 0 loss 0.9082761406898499\n",
      "tensor(7.1359, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 0 loss 0.0056969658471643925\n",
      "tensor(13.0365, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 0 loss 0.0014586533652618527\n",
      "tensor(9.0388, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 0 loss 0.013736008666455746\n",
      "tensor(7.6025, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 0 loss 0.0023838456254452467\n",
      "tensor(13.9887, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 0 loss 0.0010378933511674404\n",
      "tensor(9.8608, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 0 loss 8.451581379631534e-05\n",
      "tensor(14.0554, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 0 loss 0.03195132315158844\n",
      "tensor(7.3129, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 0 loss 0.05943484976887703\n",
      "tensor(4.7453, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 0 loss 0.028153780847787857\n",
      "tensor(6.1627, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 0 loss 0.0012207920663058758\n",
      "tensor(8.8473, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 0 loss 0.11935388296842575\n",
      "tensor(13.9483, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 0 loss 0.01421046070754528\n",
      "tensor(12.6826, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 0 loss 1.349381923675537\n",
      "tensor(15.0016, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 0 loss 0.2757229804992676\n",
      "tensor(8.0023, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 0 loss 0.030809689313173294\n",
      "tensor(12.4463, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 0 loss 0.03573622182011604\n",
      "tensor(10.3379, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 0 loss 0.0004001055203843862\n",
      "tensor(10.7917, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 0 loss 0.0017791647696867585\n",
      "tensor(9.6405, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 0 loss 0.0008447177824564278\n",
      "tensor(14.4415, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 0 loss 0.6253824234008789\n",
      "tensor(8.9406, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 0 loss 0.550289511680603\n",
      "tensor(8.7375, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 0 loss 0.4178258180618286\n",
      "tensor(19.5142, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 0 loss 0.01221061684191227\n",
      "tensor(16.0844, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 0 loss 2.525108575820923\n",
      "tensor(8.2380, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 0 loss 2.4676019165781327e-05\n",
      "tensor(12.9345, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 0 loss 0.12225876748561859\n",
      "tensor(3.9925, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 0 loss 0.0034484940115362406\n",
      "tensor(9.9311, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 0 loss 0.025319259613752365\n",
      "tensor(16.3602, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 0 loss 0.08786426484584808\n",
      "tensor(5.5653, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 0 loss 0.05617532879114151\n",
      "tensor(19.3121, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 0 loss 0.12971378862857819\n",
      "tensor(11.5238, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 0 loss 0.43400973081588745\n",
      "tensor(11.5333, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 0 loss 0.004693443886935711\n",
      "tensor(8.8277, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 0 loss 0.059187691658735275\n",
      "tensor(4.7958, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 0 loss 0.27971911430358887\n",
      "tensor(15.4759, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 0 loss 0.4860162138938904\n",
      "tensor(7.5892, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 0 loss 0.025875957682728767\n",
      "tensor(9.0277, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 0 loss 0.0057718753814697266\n",
      "tensor(5.4003, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 0 loss 0.0212057214230299\n",
      "tensor(15.8501, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 0 loss 0.042412564158439636\n",
      "tensor(10.0573, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 0 loss 0.00802613329142332\n",
      "tensor(11.3427, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 0 loss 0.004343005828559399\n",
      "tensor(10.4140, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 0 loss 2.5629668016335927e-05\n",
      "tensor(15.7937, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 0 loss 0.0026139398105442524\n",
      "tensor(9.6618, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 0 loss 0.001050040009431541\n",
      "tensor(17.3005, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 0 loss 0.007213026750832796\n",
      "tensor(15.5287, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 0 loss 0.001077905297279358\n",
      "tensor(15.3644, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 0 loss 0.009026317857205868\n",
      "tensor(13.5781, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 0 loss 0.006331266835331917\n",
      "tensor(7.6753, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 0 loss 0.0004234609368722886\n",
      "tensor(10.7046, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 0 loss 0.01355409063398838\n",
      "tensor(20.2375, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 0 loss 0.008098858408629894\n",
      "tensor(13.5499, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 0 loss 0.9203258752822876\n",
      "tensor(10.9671, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 0 loss 0.013111800886690617\n",
      "tensor(15.7806, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 0 loss 0.00027176024741493165\n",
      "tensor(13.1255, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 0 loss 5.216581344604492\n",
      "tensor(12.0396, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 1 loss 0.0051826415583491325\n",
      "tensor(12.7672, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 1 loss 0.31001198291778564\n",
      "tensor(6.2310, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 1 loss 0.004969269502907991\n",
      "tensor(15.6183, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 1 loss 0.07745446264743805\n",
      "tensor(25.1052, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 1 loss 0.013955865055322647\n",
      "tensor(9.5785, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 1 loss 0.15507657825946808\n",
      "tensor(12.6274, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 1 loss 0.0019345632754266262\n",
      "tensor(6.6483, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 1 loss 0.7165963649749756\n",
      "tensor(4.3192, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 1 loss 0.02397696115076542\n",
      "tensor(8.2324, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 1 loss 0.004335765726864338\n",
      "tensor(14.0531, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 1 loss 3.672083616256714\n",
      "tensor(12.6779, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 1 loss 0.0008628221112303436\n",
      "tensor(8.7492, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 1 loss 1.2246026992797852\n",
      "tensor(7.5341, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 1 loss 0.046434950083494186\n",
      "tensor(10.3773, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 1 loss 0.0003885467885993421\n",
      "tensor(15.2071, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 1 loss 0.08951493352651596\n",
      "tensor(10.1490, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 1 loss 0.20004841685295105\n",
      "tensor(14.1327, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 1 loss 0.0005710878176614642\n",
      "tensor(13.4956, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 1 loss 2.8643460273742676\n",
      "tensor(5.2139, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 1 loss 0.007573108654469252\n",
      "tensor(11.0511, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 1 loss 0.0002083561266772449\n",
      "tensor(11.6825, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 1 loss 0.013083916157484055\n",
      "tensor(16.1171, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 1 loss 0.00013493580627255142\n",
      "tensor(12.2664, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 1 loss 0.00023195437097456306\n",
      "tensor(15.3138, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 1 loss 0.7941558957099915\n",
      "tensor(18.6365, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 1 loss 4.499626159667969\n",
      "tensor(16.8038, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 1 loss 0.26001837849617004\n",
      "tensor(15.8790, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 1 loss 6.030898571014404\n",
      "tensor(7.7716, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 1 loss 0.49486273527145386\n",
      "tensor(9.0466, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 1 loss 0.015836656093597412\n",
      "tensor(9.7300, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 1 loss 0.025757113471627235\n",
      "tensor(20.2206, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 1 loss 0.00990110170096159\n",
      "tensor(9.3285, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 1 loss 0.45372578501701355\n",
      "tensor(14.5580, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 1 loss 0.007278118748217821\n",
      "tensor(12.1630, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 1 loss 0.3066994547843933\n",
      "tensor(4.7439, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 1 loss 0.09905675053596497\n",
      "tensor(8.0333, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 1 loss 0.0026324877981096506\n",
      "tensor(8.3870, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 1 loss 0.0014835315523669124\n",
      "tensor(16.0700, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 1 loss 0.008042097091674805\n",
      "tensor(10.4423, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 1 loss 0.0028576513286679983\n",
      "tensor(8.4322, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 1 loss 0.013104976154863834\n",
      "tensor(10.4561, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 1 loss 0.006425080355256796\n",
      "tensor(15.8911, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 1 loss 0.2232045829296112\n",
      "tensor(8.5292, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 1 loss 0.03224281966686249\n",
      "tensor(8.6937, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 1 loss 0.5987443923950195\n",
      "tensor(7.7590, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 1 loss 0.18523450195789337\n",
      "tensor(9.7460, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 1 loss 1.8240231275558472\n",
      "tensor(9.4048, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 1 loss 0.05053461343050003\n",
      "tensor(6.0184, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 1 loss 4.570857524871826\n",
      "tensor(10.0997, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 1 loss 1.324840784072876\n",
      "tensor(10.2714, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 1 loss 0.14254866540431976\n",
      "tensor(6.5977, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 1 loss 0.05774172022938728\n",
      "tensor(8.7281, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 1 loss 0.048711322247982025\n",
      "tensor(12.4422, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 1 loss 0.2542540729045868\n",
      "tensor(9.2506, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 1 loss 0.18516585230827332\n",
      "tensor(21.2226, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 1 loss 0.0020582936704158783\n",
      "tensor(14.9688, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 1 loss 0.05189857631921768\n",
      "tensor(6.3215, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 1 loss 0.00213585514575243\n",
      "tensor(12.9568, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 1 loss 0.36864668130874634\n",
      "tensor(13.6760, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 1 loss 0.0011747133685275912\n",
      "tensor(7.7710, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 2 loss 0.0651310533285141\n",
      "tensor(14.3013, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 2 loss 0.014639578759670258\n",
      "tensor(12.4553, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 2 loss 0.09304559230804443\n",
      "tensor(11.9725, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 2 loss 0.5176544785499573\n",
      "tensor(12.8034, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 2 loss 0.021922869607806206\n",
      "tensor(8.1766, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 2 loss 2.0839223861694336\n",
      "tensor(13.1418, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 2 loss 0.013268860056996346\n",
      "tensor(10.9228, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 2 loss 0.030321307480335236\n",
      "tensor(8.9029, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 2 loss 0.0003923600015696138\n",
      "tensor(11.9159, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 2 loss 0.038382649421691895\n",
      "tensor(6.6164, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 2 loss 0.06306036561727524\n",
      "tensor(9.1602, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 2 loss 0.851548433303833\n",
      "tensor(8.6389, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 2 loss 0.3398134410381317\n",
      "tensor(6.6935, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 2 loss 0.01960110105574131\n",
      "tensor(9.9765, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 2 loss 0.01714339666068554\n",
      "tensor(10.7708, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 2 loss 0.277765154838562\n",
      "tensor(7.8271, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 2 loss 0.533532440662384\n",
      "tensor(10.9027, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 2 loss 0.13135622441768646\n",
      "tensor(17.2722, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 2 loss 0.022321412339806557\n",
      "tensor(9.7045, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 2 loss 0.015874085947871208\n",
      "tensor(8.5923, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 2 loss 2.6793603897094727\n",
      "tensor(8.7568, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 2 loss 0.059699468314647675\n",
      "tensor(8.4330, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 2 loss 0.18360267579555511\n",
      "tensor(7.9509, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 2 loss 0.08454366028308868\n",
      "tensor(5.4561, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 2 loss 0.02622891776263714\n",
      "tensor(12.3385, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 2 loss 0.6466325521469116\n",
      "tensor(8.5758, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 2 loss 0.11606643348932266\n",
      "tensor(8.6415, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 2 loss 0.0265728160738945\n",
      "tensor(9.9069, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 2 loss 0.381495863199234\n",
      "tensor(14.7578, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 2 loss 0.5620948672294617\n",
      "tensor(15.4354, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 2 loss 0.48233306407928467\n",
      "tensor(20.3170, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 2 loss 0.21888694167137146\n",
      "tensor(4.8760, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 2 loss 0.20558886229991913\n",
      "tensor(7.4462, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 2 loss 0.026094553992152214\n",
      "tensor(17.7399, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 2 loss 0.0014079429674893618\n",
      "tensor(13.3046, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 2 loss 0.06444334983825684\n",
      "tensor(11.4047, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 2 loss 0.030253535136580467\n",
      "tensor(12.4644, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 2 loss 0.17462120950222015\n",
      "tensor(6.7228, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 2 loss 0.004282470792531967\n",
      "tensor(12.1332, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 2 loss 0.40584269165992737\n",
      "tensor(7.5988, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 2 loss 0.0016796779818832874\n",
      "tensor(15.2074, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 2 loss 0.002394548850134015\n",
      "tensor(11.3353, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 2 loss 0.010436010546982288\n",
      "tensor(8.9201, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 2 loss 0.09355020523071289\n",
      "tensor(6.5078, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 2 loss 0.0454726479947567\n",
      "tensor(14.5314, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 2 loss 0.0020375936292111874\n",
      "tensor(11.6334, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 2 loss 0.29625204205513\n",
      "tensor(9.2476, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 2 loss 0.10544166713953018\n",
      "tensor(8.9294, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 2 loss 0.17155367136001587\n",
      "tensor(11.2115, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 2 loss 0.5625271797180176\n",
      "tensor(16.6771, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 2 loss 0.34240543842315674\n",
      "tensor(7.6650, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 2 loss 0.013996068388223648\n",
      "tensor(12.5948, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 2 loss 2.26770281791687\n",
      "tensor(8.0414, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 2 loss 0.008698076009750366\n",
      "tensor(9.1631, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 2 loss 0.1269049495458603\n",
      "tensor(18.4098, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 2 loss 1.490782380104065\n",
      "tensor(15.4479, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 2 loss 0.6246406435966492\n",
      "tensor(18.8722, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 2 loss 0.08902125060558319\n",
      "tensor(16.1806, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 2 loss 0.8711094856262207\n",
      "tensor(10.9134, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 2 loss 0.0602007657289505\n",
      "tensor(7.4004, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 3 loss 2.9378623962402344\n",
      "tensor(6.9932, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 3 loss 2.9225242137908936\n",
      "tensor(9.1026, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 3 loss 0.10565052181482315\n",
      "tensor(4.9978, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 3 loss 0.45470085740089417\n",
      "tensor(6.4492, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 3 loss 0.594828188419342\n",
      "tensor(6.3393, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 3 loss 0.012262784875929356\n",
      "tensor(14.9290, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 3 loss 0.4074327349662781\n",
      "tensor(18.0668, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 3 loss 0.1417853981256485\n",
      "tensor(8.1784, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 3 loss 0.29949238896369934\n",
      "tensor(8.1762, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 3 loss 0.004015835467725992\n",
      "tensor(12.9948, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 3 loss 1.0951578617095947\n",
      "tensor(10.7613, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 3 loss 0.16751188039779663\n",
      "tensor(10.1538, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 3 loss 0.05072341486811638\n",
      "tensor(13.3960, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 3 loss 0.11848977953195572\n",
      "tensor(7.2359, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 3 loss 0.013097446411848068\n",
      "tensor(15.8449, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 3 loss 0.0010118131758645177\n",
      "tensor(16.0123, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 3 loss 1.9377238750457764\n",
      "tensor(6.7972, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 3 loss 0.13265569508075714\n",
      "tensor(13.9518, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 3 loss 1.3852338790893555\n",
      "tensor(7.0700, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 3 loss 0.293791800737381\n",
      "tensor(21.0996, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 3 loss 0.07881251722574234\n",
      "tensor(9.8188, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 3 loss 0.01531155500560999\n",
      "tensor(16.5871, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 3 loss 0.004895842168480158\n",
      "tensor(13.3315, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 3 loss 0.003421407425776124\n",
      "tensor(15.9392, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 3 loss 0.07965236157178879\n",
      "tensor(7.1788, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 3 loss 0.1260431408882141\n",
      "tensor(7.6543, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 3 loss 0.10685708373785019\n",
      "tensor(8.3635, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 3 loss 0.03155532851815224\n",
      "tensor(10.0724, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 3 loss 0.06876806169748306\n",
      "tensor(18.0612, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 3 loss 0.24001623690128326\n",
      "tensor(14.6655, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 3 loss 0.13708743453025818\n",
      "tensor(12.1599, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 3 loss 1.8683761358261108\n",
      "tensor(14.1645, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 3 loss 0.7925622463226318\n",
      "tensor(5.5073, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 3 loss 0.10580892860889435\n",
      "tensor(19.8326, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 3 loss 0.008991584181785583\n",
      "tensor(11.0347, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 3 loss 0.0004027270770166069\n",
      "tensor(14.4924, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 3 loss 0.0006491222884505987\n",
      "tensor(14.9804, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 3 loss 0.11363507807254791\n",
      "tensor(14.7115, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 3 loss 0.01870773918926716\n",
      "tensor(13.5110, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 3 loss 0.04165405407547951\n",
      "tensor(13.2461, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 3 loss 0.02622566558420658\n",
      "tensor(6.9157, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 3 loss 0.0074556199833750725\n",
      "tensor(15.9895, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 3 loss 0.0084605123847723\n",
      "tensor(11.6157, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 3 loss 0.5581027865409851\n",
      "tensor(9.8290, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 3 loss 0.3605392277240753\n",
      "tensor(12.0015, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 3 loss 0.06946803629398346\n",
      "tensor(10.3714, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 3 loss 3.7642152309417725\n",
      "tensor(12.2006, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 3 loss 0.06501454859972\n",
      "tensor(13.0975, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 3 loss 0.15136514604091644\n",
      "tensor(10.5321, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 3 loss 0.12544940412044525\n",
      "tensor(8.9051, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 3 loss 0.05704778805375099\n",
      "tensor(7.3473, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 3 loss 1.3592307567596436\n",
      "tensor(5.9948, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 3 loss 0.12885020673274994\n",
      "tensor(10.7732, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 3 loss 0.2822975814342499\n",
      "tensor(10.8964, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 3 loss 0.005989341530948877\n",
      "tensor(16.9895, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 3 loss 0.008939600549638271\n",
      "tensor(13.1317, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 3 loss 0.1846178025007248\n",
      "tensor(15.9164, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 3 loss 1.598588228225708\n",
      "tensor(7.7000, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 3 loss 0.08186905086040497\n",
      "tensor(19.5330, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 3 loss 0.038879841566085815\n",
      "tensor(9.1366, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 4 loss 0.019638974219560623\n",
      "tensor(17.7749, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 4 loss 0.054680295288562775\n",
      "tensor(20.3851, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 4 loss 0.3648580312728882\n",
      "tensor(14.4524, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 4 loss 0.5102612972259521\n",
      "tensor(5.8004, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 4 loss 2.7727279663085938\n",
      "tensor(11.5870, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 4 loss 0.003265526844188571\n",
      "tensor(15.7071, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 4 loss 0.717872679233551\n",
      "tensor(5.6401, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 4 loss 1.4598588943481445\n",
      "tensor(8.7023, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 4 loss 1.1998783349990845\n",
      "tensor(7.9690, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 4 loss 0.006924204993993044\n",
      "tensor(11.5438, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 4 loss 0.07320922613143921\n",
      "tensor(10.2639, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 4 loss 0.022001121193170547\n",
      "tensor(9.0052, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 4 loss 0.004559715278446674\n",
      "tensor(16.1174, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 4 loss 0.015171959064900875\n",
      "tensor(7.7027, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 4 loss 0.10885441303253174\n",
      "tensor(12.2218, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 4 loss 4.029987335205078\n",
      "tensor(9.0670, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 4 loss 0.007019028067588806\n",
      "tensor(11.0521, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 4 loss 0.006068732123821974\n",
      "tensor(15.1751, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 4 loss 0.22738640010356903\n",
      "tensor(16.7092, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 4 loss 1.095517873764038\n",
      "tensor(10.4216, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 4 loss 0.07889150828123093\n",
      "tensor(15.3889, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 4 loss 1.7718521356582642\n",
      "tensor(8.6231, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 4 loss 0.03241998329758644\n",
      "tensor(10.2655, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 4 loss 0.058207783848047256\n",
      "tensor(14.3861, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 4 loss 0.2207297533750534\n",
      "tensor(13.7139, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 4 loss 0.21937593817710876\n",
      "tensor(10.5024, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 4 loss 0.5536578297615051\n",
      "tensor(9.0802, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 4 loss 2.1925885677337646\n",
      "tensor(9.5465, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 4 loss 1.0221692323684692\n",
      "tensor(13.5746, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 4 loss 0.09509928524494171\n",
      "tensor(13.9248, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 4 loss 0.42046186327934265\n",
      "tensor(13.8020, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 4 loss 0.008684131316840649\n",
      "tensor(13.4009, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 4 loss 0.04666241258382797\n",
      "tensor(14.9670, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 4 loss 1.048834204673767\n",
      "tensor(6.1475, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 4 loss 1.5436933040618896\n",
      "tensor(12.1236, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 4 loss 0.002281088614836335\n",
      "tensor(16.7293, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 4 loss 0.056123148649930954\n",
      "tensor(12.6864, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 4 loss 0.05471246317028999\n",
      "tensor(18.2014, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 4 loss 0.11222848296165466\n",
      "tensor(11.3658, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 4 loss 0.7705233097076416\n",
      "tensor(8.3475, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 4 loss 0.5154634714126587\n",
      "tensor(8.8942, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 4 loss 0.8748501539230347\n",
      "tensor(8.4590, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 4 loss 0.12724268436431885\n",
      "tensor(7.5426, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 4 loss 0.1075439602136612\n",
      "tensor(12.8670, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 4 loss 0.008834915235638618\n",
      "tensor(12.2715, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 4 loss 0.027674071490764618\n",
      "tensor(8.2206, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 4 loss 0.03634704649448395\n",
      "tensor(13.8643, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 4 loss 0.01923632062971592\n",
      "tensor(14.5322, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 4 loss 0.01385029312223196\n",
      "tensor(9.4340, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 4 loss 0.034550078213214874\n",
      "tensor(12.2847, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 4 loss 0.015971582382917404\n",
      "tensor(9.3457, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 4 loss 0.012434929609298706\n",
      "tensor(9.0829, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 4 loss 0.0005021026590839028\n",
      "tensor(13.1562, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 4 loss 2.156773805618286\n",
      "tensor(11.4363, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 4 loss 0.05595306307077408\n",
      "tensor(17.9009, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 4 loss 0.2756926417350769\n",
      "tensor(9.6721, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 4 loss 0.4736034572124481\n",
      "tensor(6.7908, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 4 loss 0.007215749006718397\n",
      "tensor(19.7335, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 4 loss 0.2305866777896881\n",
      "tensor(8.3432, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 4 loss 0.4367696940898895\n",
      "tensor(14.1920, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 5 loss 0.44022369384765625\n",
      "tensor(12.3464, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 5 loss 0.05892406404018402\n",
      "tensor(15.9563, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 5 loss 0.2548369765281677\n",
      "tensor(12.4129, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 5 loss 0.40127065777778625\n",
      "tensor(13.7975, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 5 loss 0.24154233932495117\n",
      "tensor(15.5927, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 5 loss 1.7095509767532349\n",
      "tensor(15.5536, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 5 loss 0.016041386872529984\n",
      "tensor(10.5890, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 5 loss 0.002964152256026864\n",
      "tensor(13.8369, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 5 loss 0.00851027574390173\n",
      "tensor(15.7526, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 5 loss 0.2646743953227997\n",
      "tensor(5.6167, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 5 loss 0.04772200062870979\n",
      "tensor(10.0958, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 5 loss 0.042568743228912354\n",
      "tensor(8.5004, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 5 loss 0.013189921155571938\n",
      "tensor(9.1000, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 5 loss 0.02277759276330471\n",
      "tensor(8.2415, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 5 loss 0.005266720429062843\n",
      "tensor(15.3983, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 5 loss 0.08655475080013275\n",
      "tensor(15.0471, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 5 loss 0.4274998903274536\n",
      "tensor(12.4851, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 5 loss 0.007690228521823883\n",
      "tensor(19.5672, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 5 loss 0.6821643114089966\n",
      "tensor(5.8320, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 5 loss 0.48082149028778076\n",
      "tensor(20.5229, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 5 loss 0.5643928647041321\n",
      "tensor(5.4089, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 5 loss 0.24520903825759888\n",
      "tensor(17.4875, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 5 loss 0.7934895157814026\n",
      "tensor(8.3652, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 5 loss 0.09694019705057144\n",
      "tensor(14.5860, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 5 loss 0.0960954800248146\n",
      "tensor(12.7478, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 5 loss 0.13254983723163605\n",
      "tensor(10.2127, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 5 loss 0.05266960337758064\n",
      "tensor(18.8012, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 5 loss 1.9248502254486084\n",
      "tensor(18.3660, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 5 loss 0.11225874722003937\n",
      "tensor(7.0095, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 5 loss 0.04768688231706619\n",
      "tensor(8.4950, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 5 loss 0.09552323818206787\n",
      "tensor(10.6694, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 5 loss 0.009154017083346844\n",
      "tensor(10.9375, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 5 loss 0.01696116104722023\n",
      "tensor(11.5985, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 5 loss 0.06387898325920105\n",
      "tensor(9.9538, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 5 loss 0.055221229791641235\n",
      "tensor(10.9286, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 5 loss 0.9499218463897705\n",
      "tensor(8.0708, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 5 loss 0.19491137564182281\n",
      "tensor(14.0547, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 5 loss 1.067832350730896\n",
      "tensor(6.5613, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 5 loss 0.023877330124378204\n",
      "tensor(7.5761, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 5 loss 0.00502774678170681\n",
      "tensor(11.2591, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 5 loss 0.2544502317905426\n",
      "tensor(9.4247, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 5 loss 0.324582040309906\n",
      "tensor(15.2773, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 5 loss 0.03936039283871651\n",
      "tensor(11.8167, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 5 loss 0.763862133026123\n",
      "tensor(9.4490, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 5 loss 0.24195225536823273\n",
      "tensor(13.4744, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 5 loss 0.07453089952468872\n",
      "tensor(7.7148, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 5 loss 0.835978627204895\n",
      "tensor(10.1278, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 5 loss 0.034497104585170746\n",
      "tensor(6.7092, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 5 loss 0.3842184245586395\n",
      "tensor(5.4798, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 5 loss 0.6913820505142212\n",
      "tensor(9.9019, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 5 loss 0.04671861603856087\n",
      "tensor(7.9281, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 5 loss 1.7682883739471436\n",
      "tensor(8.4195, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 5 loss 0.11611133068799973\n",
      "tensor(11.8606, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 5 loss 0.2818637788295746\n",
      "tensor(7.3025, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 5 loss 2.3448665142059326\n",
      "tensor(9.2729, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 5 loss 0.01712171733379364\n",
      "tensor(11.7545, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 5 loss 0.24854032695293427\n",
      "tensor(9.7927, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 5 loss 2.7050321102142334\n",
      "tensor(12.3123, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 5 loss 1.609938383102417\n",
      "tensor(18.9813, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 5 loss 0.6877326369285583\n",
      "tensor(5.5678, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 6 loss 0.4043515622615814\n",
      "tensor(10.4841, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 6 loss 0.6819185018539429\n",
      "tensor(12.9111, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 6 loss 1.2182066440582275\n",
      "tensor(14.6633, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 6 loss 0.004587483126670122\n",
      "tensor(14.5262, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 6 loss 0.040569353848695755\n",
      "tensor(10.3857, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 6 loss 0.05582274869084358\n",
      "tensor(6.9639, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 6 loss 0.143089160323143\n",
      "tensor(14.3022, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 6 loss 0.25306376814842224\n",
      "tensor(11.2471, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 6 loss 0.12335401028394699\n",
      "tensor(16.3375, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 6 loss 0.0188586562871933\n",
      "tensor(9.0040, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 6 loss 0.009818592108786106\n",
      "tensor(15.2637, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 6 loss 0.00690076407045126\n",
      "tensor(14.3085, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 6 loss 0.044994112104177475\n",
      "tensor(9.3892, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 6 loss 0.24948377907276154\n",
      "tensor(14.5819, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 6 loss 0.0022653888445347548\n",
      "tensor(14.5378, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 6 loss 0.037403952330350876\n",
      "tensor(14.7745, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 6 loss 0.0018156962469220161\n",
      "tensor(15.8313, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 6 loss 0.3681127429008484\n",
      "tensor(9.2949, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 6 loss 0.006264455150812864\n",
      "tensor(18.9803, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 6 loss 0.007921706885099411\n",
      "tensor(12.7823, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 6 loss 0.003195063676685095\n",
      "tensor(16.8242, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 6 loss 0.959417462348938\n",
      "tensor(24.5073, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 6 loss 0.045632679015398026\n",
      "tensor(6.7889, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 6 loss 0.15944410860538483\n",
      "tensor(12.0198, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 6 loss 0.11400071531534195\n",
      "tensor(10.8126, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 6 loss 0.14358040690422058\n",
      "tensor(12.6746, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 6 loss 0.15125027298927307\n",
      "tensor(10.4006, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 6 loss 0.04768165200948715\n",
      "tensor(13.8637, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 6 loss 0.3594844937324524\n",
      "tensor(16.6676, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 6 loss 1.0930211544036865\n",
      "tensor(5.7665, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 6 loss 0.1916477233171463\n",
      "tensor(17.8902, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 6 loss 1.8683624267578125\n",
      "tensor(9.9051, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 6 loss 0.018882403150200844\n",
      "tensor(20.6088, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 6 loss 0.09335466474294662\n",
      "tensor(9.4003, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 6 loss 0.015096928924322128\n",
      "tensor(10.8565, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 6 loss 0.0025366530753672123\n",
      "tensor(14.6329, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 6 loss 0.22397318482398987\n",
      "tensor(14.9692, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 6 loss 0.005451218690723181\n",
      "tensor(17.5699, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 6 loss 0.1557496041059494\n",
      "tensor(15.2591, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 6 loss 0.18669158220291138\n",
      "tensor(15.1776, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 6 loss 0.44834157824516296\n",
      "tensor(18.3739, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 6 loss 0.0017667888896539807\n",
      "tensor(15.3736, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 6 loss 0.0178570207208395\n",
      "tensor(10.8851, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 6 loss 0.03723892197012901\n",
      "tensor(9.6948, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 6 loss 3.5420444011688232\n",
      "tensor(9.0337, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 6 loss 0.009995643980801105\n",
      "tensor(13.3623, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 6 loss 0.561330258846283\n",
      "tensor(13.5458, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 6 loss 0.047960419207811356\n",
      "tensor(19.7467, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 6 loss 0.01853456348180771\n",
      "tensor(11.5036, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 6 loss 0.42438939213752747\n",
      "tensor(12.3108, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 6 loss 0.13216814398765564\n",
      "tensor(13.3897, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 6 loss 0.17589057981967926\n",
      "tensor(10.5105, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 6 loss 0.32592612504959106\n",
      "tensor(10.0190, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 6 loss 0.008547743782401085\n",
      "tensor(18.9125, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 6 loss 0.07533840835094452\n",
      "tensor(7.7969, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 6 loss 0.08031780272722244\n",
      "tensor(13.8070, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 6 loss 0.0015963680343702435\n",
      "tensor(19.1204, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 6 loss 0.08210253715515137\n",
      "tensor(9.3474, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 6 loss 0.00935598649084568\n",
      "tensor(13.4563, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 6 loss 1.1167283058166504\n",
      "tensor(14.9509, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 7 loss 0.8266232013702393\n",
      "tensor(18.3827, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 7 loss 0.0066903638653457165\n",
      "tensor(14.7657, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 7 loss 0.04304444417357445\n",
      "tensor(9.2417, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 7 loss 0.0021971152164041996\n",
      "tensor(15.6707, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 7 loss 0.002997312694787979\n",
      "tensor(17.2500, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 7 loss 0.1461125761270523\n",
      "tensor(11.8653, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 7 loss 0.5846037268638611\n",
      "tensor(10.2498, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 7 loss 0.02017723023891449\n",
      "tensor(14.3667, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 7 loss 0.011254752986133099\n",
      "tensor(17.9021, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 7 loss 2.277367353439331\n",
      "tensor(12.2979, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 7 loss 0.03250076249241829\n",
      "tensor(17.7481, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 7 loss 0.6454784870147705\n",
      "tensor(15.7251, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 7 loss 0.057631444185972214\n",
      "tensor(15.9077, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 7 loss 0.006547427270561457\n",
      "tensor(9.5130, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 7 loss 0.09388105571269989\n",
      "tensor(18.6227, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 7 loss 0.06631853431463242\n",
      "tensor(19.4105, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 7 loss 0.1568036824464798\n",
      "tensor(11.9057, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 7 loss 0.001468176138587296\n",
      "tensor(19.5984, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 7 loss 0.1787959337234497\n",
      "tensor(9.5776, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 7 loss 0.9071520566940308\n",
      "tensor(9.6867, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 7 loss 0.024032708257436752\n",
      "tensor(10.8093, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 7 loss 0.005533022340387106\n",
      "tensor(15.1261, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 7 loss 0.2849579155445099\n",
      "tensor(11.3386, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 7 loss 0.049658264964818954\n",
      "tensor(8.8366, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 7 loss 0.14559628069400787\n",
      "tensor(9.3294, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 7 loss 0.1061176285147667\n",
      "tensor(13.5383, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 7 loss 0.017897771671414375\n",
      "tensor(11.9859, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 7 loss 0.06670144200325012\n",
      "tensor(12.1202, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 7 loss 0.027702247723937035\n",
      "tensor(8.5352, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 7 loss 0.28117477893829346\n",
      "tensor(11.2488, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 7 loss 0.004892876371741295\n",
      "tensor(18.8906, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 7 loss 0.026385324075818062\n",
      "tensor(15.4679, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 7 loss 0.059992529451847076\n",
      "tensor(10.1222, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 7 loss 0.022424926981329918\n",
      "tensor(12.7238, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 7 loss 0.10170350223779678\n",
      "tensor(17.7808, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 7 loss 0.01736941747367382\n",
      "tensor(10.9365, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 7 loss 0.16960509121418\n",
      "tensor(17.2210, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 7 loss 1.981101155281067\n",
      "tensor(9.4210, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 7 loss 2.3853468894958496\n",
      "tensor(12.7950, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 7 loss 2.041168689727783\n",
      "tensor(9.6849, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 7 loss 0.13022536039352417\n",
      "tensor(12.9796, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 7 loss 0.0029091201722621918\n",
      "tensor(14.1623, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 7 loss 0.9922816753387451\n",
      "tensor(12.9534, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 7 loss 0.06497970223426819\n",
      "tensor(7.5493, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 7 loss 0.014434795826673508\n",
      "tensor(10.7441, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 7 loss 0.2747901976108551\n",
      "tensor(23.2230, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 7 loss 0.6983146071434021\n",
      "tensor(14.0107, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 7 loss 0.21980325877666473\n",
      "tensor(12.3944, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 7 loss 0.04532591998577118\n",
      "tensor(15.7743, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 7 loss 0.30919820070266724\n",
      "tensor(11.7297, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 7 loss 0.01732630282640457\n",
      "tensor(19.8891, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 7 loss 0.05655425786972046\n",
      "tensor(16.4833, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 7 loss 0.2542920708656311\n",
      "tensor(15.3448, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 7 loss 0.017668824642896652\n",
      "tensor(18.4100, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 7 loss 0.1381332278251648\n",
      "tensor(8.6583, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 7 loss 0.10571230202913284\n",
      "tensor(19.1892, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 7 loss 0.18409842252731323\n",
      "tensor(11.5190, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 7 loss 1.0362205505371094\n",
      "tensor(11.4847, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 7 loss 0.2574354410171509\n",
      "tensor(13.3431, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 7 loss 0.003322083968669176\n",
      "tensor(21.5274, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 8 loss 0.009469237178564072\n",
      "tensor(16.4987, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 8 loss 0.31124192476272583\n",
      "tensor(16.7866, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 8 loss 0.5725628137588501\n",
      "tensor(7.6539, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 8 loss 0.17042122781276703\n",
      "tensor(12.9844, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 8 loss 0.0403219535946846\n",
      "tensor(18.1379, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 8 loss 1.2384556531906128\n",
      "tensor(15.7617, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 8 loss 0.9683436155319214\n",
      "tensor(13.4527, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 8 loss 0.11454229056835175\n",
      "tensor(17.8962, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 8 loss 0.3907807469367981\n",
      "tensor(17.5344, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 8 loss 0.011602542363107204\n",
      "tensor(19.4744, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 8 loss 0.01522244606167078\n",
      "tensor(19.5359, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 8 loss 0.041381530463695526\n",
      "tensor(9.6660, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 8 loss 1.895438551902771\n",
      "tensor(11.4476, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 8 loss 1.3073608875274658\n",
      "tensor(17.2598, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 8 loss 0.06673813611268997\n",
      "tensor(10.0286, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 8 loss 0.016310933977365494\n",
      "tensor(20.1307, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 8 loss 1.1636619567871094\n",
      "tensor(10.3137, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 8 loss 0.7510343790054321\n",
      "tensor(20.7485, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 8 loss 0.003067195415496826\n",
      "tensor(15.7498, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 8 loss 0.45123469829559326\n",
      "tensor(11.9369, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 8 loss 0.02130281925201416\n",
      "tensor(9.6886, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 8 loss 0.012853040359914303\n",
      "tensor(13.8327, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 8 loss 0.013759289868175983\n",
      "tensor(15.0340, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 8 loss 0.03817395120859146\n",
      "tensor(15.4000, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 8 loss 0.07638341188430786\n",
      "tensor(19.4215, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 8 loss 0.5089994072914124\n",
      "tensor(12.7448, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 8 loss 0.10595851391553879\n",
      "tensor(15.4691, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 8 loss 0.019635116681456566\n",
      "tensor(13.5866, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 8 loss 0.0014435357879847288\n",
      "tensor(21.2935, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 8 loss 0.005423237569630146\n",
      "tensor(16.5674, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 8 loss 0.05424961820244789\n",
      "tensor(18.9851, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 8 loss 0.2862584590911865\n",
      "tensor(11.9355, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 8 loss 0.10397311300039291\n",
      "tensor(14.8637, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 8 loss 0.0017973711946979165\n",
      "tensor(19.2795, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 8 loss 0.2207881659269333\n",
      "tensor(11.6197, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 8 loss 0.07329907268285751\n",
      "tensor(18.3951, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 8 loss 0.8572230339050293\n",
      "tensor(10.7963, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 8 loss 0.027351314201951027\n",
      "tensor(12.9966, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 8 loss 0.39983683824539185\n",
      "tensor(15.7311, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 8 loss 0.045690421015024185\n",
      "tensor(16.3645, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 8 loss 0.482199490070343\n",
      "tensor(7.9219, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 8 loss 0.23237945139408112\n",
      "tensor(17.5270, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 8 loss 0.0020731640979647636\n",
      "tensor(16.8642, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 8 loss 0.4141237437725067\n",
      "tensor(8.2151, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 8 loss 0.9212286472320557\n",
      "tensor(13.7225, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 8 loss 0.043156228959560394\n",
      "tensor(15.5536, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 8 loss 0.13481517136096954\n",
      "tensor(13.9357, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 8 loss 0.008695121854543686\n",
      "tensor(15.0663, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 8 loss 0.023140618577599525\n",
      "tensor(19.3933, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 8 loss 0.031946588307619095\n",
      "tensor(12.8914, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 8 loss 0.10814778506755829\n",
      "tensor(18.3065, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 8 loss 0.3608417809009552\n",
      "tensor(13.7524, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 8 loss 0.5125910639762878\n",
      "tensor(16.9338, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 8 loss 1.5555717945098877\n",
      "tensor(10.5615, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 8 loss 0.589413583278656\n",
      "tensor(14.8439, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 8 loss 0.02936732769012451\n",
      "tensor(13.6681, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 8 loss 0.4036286473274231\n",
      "tensor(8.4569, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 8 loss 0.9305184483528137\n",
      "tensor(17.3723, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 8 loss 0.002776222536340356\n",
      "tensor(17.7454, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 8 loss 0.01037584338337183\n",
      "tensor(18.2622, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 9 loss 0.09750579297542572\n",
      "tensor(20.0399, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 9 loss 0.19692017138004303\n",
      "tensor(13.8606, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 9 loss 0.23808051645755768\n",
      "tensor(13.1839, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 9 loss 0.2609422504901886\n",
      "tensor(12.2269, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 9 loss 0.036621060222387314\n",
      "tensor(15.2998, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 9 loss 0.00998856220394373\n",
      "tensor(11.7646, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 9 loss 0.02863488160073757\n",
      "tensor(10.2842, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 9 loss 0.00939117930829525\n",
      "tensor(16.4772, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 9 loss 0.12852004170417786\n",
      "tensor(15.0430, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 9 loss 0.2528107762336731\n",
      "tensor(15.1994, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 9 loss 0.06955844908952713\n",
      "tensor(20.0250, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 9 loss 2.3415422439575195\n",
      "tensor(14.0490, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 9 loss 0.9004345536231995\n",
      "tensor(12.7351, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 9 loss 0.06639361381530762\n",
      "tensor(10.7704, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 9 loss 0.0410955473780632\n",
      "tensor(18.0854, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 9 loss 0.0606398805975914\n",
      "tensor(24.0058, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 9 loss 0.0526869036257267\n",
      "tensor(13.6063, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 9 loss 0.20493720471858978\n",
      "tensor(11.1929, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 9 loss 0.13222871720790863\n",
      "tensor(11.7000, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 9 loss 1.210195779800415\n",
      "tensor(12.4516, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 9 loss 0.20216000080108643\n",
      "tensor(9.8129, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 9 loss 0.10027226060628891\n",
      "tensor(9.3763, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 9 loss 0.003279666416347027\n",
      "tensor(16.5915, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 9 loss 0.5403578281402588\n",
      "tensor(11.6053, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 9 loss 0.026512915268540382\n",
      "tensor(21.0478, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 9 loss 0.012914941646158695\n",
      "tensor(13.7823, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 9 loss 0.019325073808431625\n",
      "tensor(15.1514, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 9 loss 0.871990978717804\n",
      "tensor(11.5747, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 9 loss 0.02280276268720627\n",
      "tensor(16.0165, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 9 loss 0.02227594517171383\n",
      "tensor(21.2904, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 9 loss 0.04509120434522629\n",
      "tensor(16.6636, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 9 loss 0.024137327447533607\n",
      "tensor(14.5515, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 9 loss 0.00603887252509594\n",
      "tensor(18.4845, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 9 loss 0.23584210872650146\n",
      "tensor(19.5472, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 9 loss 0.497913122177124\n",
      "tensor(11.1137, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 9 loss 0.01829078048467636\n",
      "tensor(12.6769, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 9 loss 1.0763165950775146\n",
      "tensor(17.5859, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 9 loss 0.024455422535538673\n",
      "tensor(20.9750, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 9 loss 0.017925288528203964\n",
      "tensor(11.7397, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 9 loss 0.07622679322957993\n",
      "tensor(16.3263, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 9 loss 3.13887882232666\n",
      "tensor(22.9873, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 9 loss 0.3445979654788971\n",
      "tensor(11.4774, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 9 loss 0.10444755107164383\n",
      "tensor(17.4350, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 9 loss 0.4695558249950409\n",
      "tensor(18.5657, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 9 loss 0.5912463665008545\n",
      "tensor(14.8941, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 9 loss 0.0030448525212705135\n",
      "tensor(21.0730, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 9 loss 0.11855542659759521\n",
      "tensor(17.2970, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 9 loss 0.1744396835565567\n",
      "tensor(10.5901, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 9 loss 0.05898677557706833\n",
      "tensor(25.9090, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 9 loss 0.12495484948158264\n",
      "tensor(14.6114, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 9 loss 1.947748064994812\n",
      "tensor(14.3939, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 9 loss 0.12600836157798767\n",
      "tensor(16.7094, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 9 loss 0.0030985698103904724\n",
      "tensor(21.0841, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 9 loss 0.0040259272791445255\n",
      "tensor(17.0864, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 9 loss 1.0418689250946045\n",
      "tensor(19.4299, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 9 loss 0.010553032159805298\n",
      "tensor(20.3574, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 9 loss 0.024294525384902954\n",
      "tensor(14.9488, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 9 loss 0.008518786169588566\n",
      "tensor(25.8153, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 9 loss 0.05047624558210373\n",
      "tensor(11.2843, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 9 loss 0.378688246011734\n",
      "tensor(9.4145, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 10 loss 0.7091541290283203\n",
      "tensor(14.7129, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 10 loss 0.20603086054325104\n",
      "tensor(11.1001, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 10 loss 0.040946461260318756\n",
      "tensor(14.5143, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 10 loss 0.2563927471637726\n",
      "tensor(10.4199, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 10 loss 1.4914008378982544\n",
      "tensor(13.1059, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 10 loss 0.5288150906562805\n",
      "tensor(19.3702, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 10 loss 0.25705912709236145\n",
      "tensor(13.7258, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 10 loss 0.13682974874973297\n",
      "tensor(13.6511, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 10 loss 0.006510594394057989\n",
      "tensor(22.1549, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 10 loss 0.06820902228355408\n",
      "tensor(14.8632, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 10 loss 0.04049254208803177\n",
      "tensor(9.7710, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 10 loss 1.2783045768737793\n",
      "tensor(19.3112, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 10 loss 0.047027673572301865\n",
      "tensor(16.4139, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 10 loss 0.013660164549946785\n",
      "tensor(16.7405, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 10 loss 0.1338633894920349\n",
      "tensor(11.1911, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 10 loss 0.4569810628890991\n",
      "tensor(13.6149, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 10 loss 0.17293284833431244\n",
      "tensor(19.8282, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 10 loss 0.0017266854410991073\n",
      "tensor(21.2780, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 10 loss 1.4624953269958496\n",
      "tensor(11.5510, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 10 loss 0.07970167696475983\n",
      "tensor(8.7875, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 10 loss 0.043759796768426895\n",
      "tensor(12.8339, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 10 loss 0.4494921863079071\n",
      "tensor(13.2101, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 10 loss 0.1416575163602829\n",
      "tensor(14.0761, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 10 loss 0.3078741729259491\n",
      "tensor(11.0085, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 10 loss 0.06972145289182663\n",
      "tensor(13.8239, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 10 loss 0.09366104751825333\n",
      "tensor(16.8168, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 10 loss 1.144923448562622\n",
      "tensor(14.4255, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 10 loss 0.006410155910998583\n",
      "tensor(22.1337, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 10 loss 0.009904171340167522\n",
      "tensor(16.1103, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 10 loss 0.4622303545475006\n",
      "tensor(12.7389, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 10 loss 0.08272575587034225\n",
      "tensor(8.3387, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 10 loss 0.06782379746437073\n",
      "tensor(17.6535, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 10 loss 0.0019270675256848335\n",
      "tensor(19.5797, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 10 loss 0.018175246194005013\n",
      "tensor(11.9945, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 10 loss 0.010459604673087597\n",
      "tensor(13.4761, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 10 loss 0.01600947603583336\n",
      "tensor(15.7178, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 10 loss 2.5202975273132324\n",
      "tensor(16.7187, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 10 loss 0.046739205718040466\n",
      "tensor(11.9683, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 10 loss 0.014901282265782356\n",
      "tensor(23.7695, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 10 loss 0.004265140276402235\n",
      "tensor(20.9496, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 10 loss 0.01984783634543419\n",
      "tensor(21.4993, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 10 loss 0.5721048712730408\n",
      "tensor(16.1610, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 10 loss 0.08239789307117462\n",
      "tensor(18.1289, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 10 loss 0.012418446131050587\n",
      "tensor(17.0852, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 10 loss 0.01965557225048542\n",
      "tensor(13.6239, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 10 loss 0.2054862678050995\n",
      "tensor(9.6632, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 10 loss 0.016372621059417725\n",
      "tensor(15.7263, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 10 loss 0.37565338611602783\n",
      "tensor(18.8802, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 10 loss 0.011492714285850525\n",
      "tensor(26.4872, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 10 loss 0.012367110699415207\n",
      "tensor(22.7824, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 10 loss 0.012663429602980614\n",
      "tensor(15.8406, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 10 loss 0.0004503904783632606\n",
      "tensor(21.3839, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 10 loss 0.03923122212290764\n",
      "tensor(17.4475, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 10 loss 0.14038699865341187\n",
      "tensor(15.7253, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 10 loss 0.30777332186698914\n",
      "tensor(14.3100, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 10 loss 1.982275128364563\n",
      "tensor(10.0826, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 10 loss 0.011030529625713825\n",
      "tensor(10.5998, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 10 loss 0.026511752977967262\n",
      "tensor(11.6457, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 10 loss 0.011073680594563484\n",
      "tensor(22.7560, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 10 loss 0.07414743304252625\n",
      "tensor(22.0757, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 11 loss 0.004575022961944342\n",
      "tensor(14.6629, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 11 loss 0.03166574612259865\n",
      "tensor(19.7906, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 11 loss 0.05760904774069786\n",
      "tensor(10.8070, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 11 loss 0.4642300307750702\n",
      "tensor(21.4725, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 11 loss 0.011199821718037128\n",
      "tensor(17.7780, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 11 loss 0.003570849308744073\n",
      "tensor(18.9552, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 11 loss 0.0013434203574433923\n",
      "tensor(21.5413, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 11 loss 0.0005550036439672112\n",
      "tensor(21.3676, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 11 loss 0.3560841679573059\n",
      "tensor(11.4958, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 11 loss 0.24232223629951477\n",
      "tensor(19.1755, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 11 loss 0.015536229126155376\n",
      "tensor(13.5864, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 11 loss 0.0013017522869631648\n",
      "tensor(20.0134, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 11 loss 0.05541320517659187\n",
      "tensor(20.0765, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 11 loss 1.6981124877929688\n",
      "tensor(14.3823, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 11 loss 0.6587882041931152\n",
      "tensor(19.0531, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 11 loss 0.3303650915622711\n",
      "tensor(14.7257, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 11 loss 0.47725480794906616\n",
      "tensor(15.9511, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 11 loss 0.011667231097817421\n",
      "tensor(18.2540, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 11 loss 0.02622229792177677\n",
      "tensor(15.7897, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 11 loss 0.06942577660083771\n",
      "tensor(16.0308, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 11 loss 0.2203933745622635\n",
      "tensor(13.2688, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 11 loss 0.39583492279052734\n",
      "tensor(21.5630, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 11 loss 0.05930880829691887\n",
      "tensor(21.9724, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 11 loss 0.13974356651306152\n",
      "tensor(17.1068, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 11 loss 1.794529914855957\n",
      "tensor(16.3762, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 11 loss 0.09930159151554108\n",
      "tensor(24.5885, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 11 loss 0.2836901843547821\n",
      "tensor(20.1698, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 11 loss 0.18338258564472198\n",
      "tensor(13.1770, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 11 loss 0.19103014469146729\n",
      "tensor(11.1346, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 11 loss 0.19703705608844757\n",
      "tensor(14.9448, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 11 loss 0.3272300064563751\n",
      "tensor(14.5874, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 11 loss 0.006337663624435663\n",
      "tensor(13.2908, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 11 loss 0.3071810305118561\n",
      "tensor(15.4582, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 11 loss 0.9513503313064575\n",
      "tensor(16.9371, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 11 loss 0.008718402124941349\n",
      "tensor(18.6630, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 11 loss 0.1331086903810501\n",
      "tensor(9.2757, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 11 loss 0.020020317286252975\n",
      "tensor(16.8614, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 11 loss 0.006241354160010815\n",
      "tensor(17.8645, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 11 loss 0.1782594472169876\n",
      "tensor(17.6767, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 11 loss 0.22308728098869324\n",
      "tensor(16.2308, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 11 loss 0.2066241055727005\n",
      "tensor(11.1288, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 11 loss 0.051749277859926224\n",
      "tensor(18.5032, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 11 loss 0.06324771046638489\n",
      "tensor(9.9149, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 11 loss 0.5634571313858032\n",
      "tensor(20.1330, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 11 loss 1.9606821537017822\n",
      "tensor(14.2279, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 11 loss 0.044790662825107574\n",
      "tensor(21.0180, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 11 loss 0.2211141735315323\n",
      "tensor(14.1895, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 11 loss 0.6509320139884949\n",
      "tensor(9.9502, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 11 loss 0.0041237566620111465\n",
      "tensor(22.4789, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 11 loss 0.01687583141028881\n",
      "tensor(15.9892, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 11 loss 0.10187362879514694\n",
      "tensor(16.7266, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 11 loss 0.09487965703010559\n",
      "tensor(19.9960, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 11 loss 0.013266624882817268\n",
      "tensor(26.3088, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 11 loss 0.12153853476047516\n",
      "tensor(21.6405, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 11 loss 0.07359183579683304\n",
      "tensor(18.3994, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 11 loss 0.03472130745649338\n",
      "tensor(16.5096, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 11 loss 0.10598167777061462\n",
      "tensor(23.0379, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 11 loss 0.1398662030696869\n",
      "tensor(15.3139, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 11 loss 0.05568159371614456\n",
      "tensor(21.1920, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 11 loss 0.00995976384729147\n",
      "tensor(19.7237, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 12 loss 0.34647420048713684\n",
      "tensor(16.3849, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 12 loss 0.03727934882044792\n",
      "tensor(18.7117, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 12 loss 0.1620437353849411\n",
      "tensor(17.3448, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 12 loss 0.09815060347318649\n",
      "tensor(18.9126, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 12 loss 0.03721468895673752\n",
      "tensor(22.9234, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 12 loss 0.000766102981287986\n",
      "tensor(21.7579, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 12 loss 1.7779844999313354\n",
      "tensor(19.7825, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 12 loss 0.005392884835600853\n",
      "tensor(14.1751, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 12 loss 0.04216344654560089\n",
      "tensor(12.7775, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 12 loss 0.038910914212465286\n",
      "tensor(11.0680, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 12 loss 0.010392006486654282\n",
      "tensor(17.9460, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 12 loss 0.027537930756807327\n",
      "tensor(16.7945, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 12 loss 0.0009716795175336301\n",
      "tensor(20.8977, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 12 loss 0.002386342966929078\n",
      "tensor(20.4763, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 12 loss 0.32160672545433044\n",
      "tensor(19.3593, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 12 loss 0.015703469514846802\n",
      "tensor(10.8348, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 12 loss 0.39166024327278137\n",
      "tensor(15.8957, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 12 loss 0.028069285675883293\n",
      "tensor(16.7027, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 12 loss 0.008752790279686451\n",
      "tensor(18.2473, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 12 loss 0.04327930137515068\n",
      "tensor(18.6682, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 12 loss 0.025371676310896873\n",
      "tensor(19.5682, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 12 loss 0.0019966682884842157\n",
      "tensor(16.9805, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 12 loss 0.0038745347410440445\n",
      "tensor(23.2382, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 12 loss 0.009207288734614849\n",
      "tensor(22.7026, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 12 loss 0.12385199218988419\n",
      "tensor(15.2390, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 12 loss 0.1348688155412674\n",
      "tensor(9.1290, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 12 loss 0.003328143386170268\n",
      "tensor(23.0459, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 12 loss 0.019498812034726143\n",
      "tensor(20.7267, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 12 loss 0.050464797765016556\n",
      "tensor(19.2931, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 12 loss 0.010545010678470135\n",
      "tensor(20.0122, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 12 loss 0.1219959557056427\n",
      "tensor(21.1627, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 12 loss 0.1391185075044632\n",
      "tensor(19.8724, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 12 loss 0.018278490751981735\n",
      "tensor(14.0721, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 12 loss 0.07067648321390152\n",
      "tensor(20.1943, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 12 loss 1.8421493768692017\n",
      "tensor(17.7768, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 12 loss 0.01047718245536089\n",
      "tensor(13.6977, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 12 loss 0.05599488317966461\n",
      "tensor(20.8843, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 12 loss 2.1902360916137695\n",
      "tensor(25.3799, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 12 loss 0.32161223888397217\n",
      "tensor(12.9621, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 12 loss 0.017710987478494644\n",
      "tensor(14.4836, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 12 loss 0.01313650794327259\n",
      "tensor(16.6697, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 12 loss 0.13024869561195374\n",
      "tensor(17.8962, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 12 loss 0.17356890439987183\n",
      "tensor(25.6885, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 12 loss 0.4294380247592926\n",
      "tensor(12.0869, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 12 loss 0.021055974066257477\n",
      "tensor(17.1352, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 12 loss 0.017095351591706276\n",
      "tensor(22.7057, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 12 loss 0.12360329180955887\n",
      "tensor(10.9523, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 12 loss 0.1478385627269745\n",
      "tensor(15.0764, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 12 loss 0.045214951038360596\n",
      "tensor(13.4739, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 12 loss 2.015153169631958\n",
      "tensor(16.1019, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 12 loss 0.3052574098110199\n",
      "tensor(10.5192, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 12 loss 0.08760350197553635\n",
      "tensor(17.8921, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 12 loss 0.004828934092074633\n",
      "tensor(20.9790, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 12 loss 0.9579943418502808\n",
      "tensor(10.2988, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 12 loss 0.05002254992723465\n",
      "tensor(17.8701, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 12 loss 0.0006132629350759089\n",
      "tensor(23.8008, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 12 loss 0.08557165414094925\n",
      "tensor(14.7265, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 12 loss 0.172062948346138\n",
      "tensor(11.1638, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 12 loss 0.012767596170306206\n",
      "tensor(19.1865, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 12 loss 0.19224032759666443\n",
      "tensor(11.5010, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 13 loss 0.0030107428319752216\n",
      "tensor(19.2492, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 13 loss 0.18849295377731323\n",
      "tensor(9.3499, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 13 loss 0.037936288863420486\n",
      "tensor(12.8311, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 13 loss 3.1231346130371094\n",
      "tensor(15.1402, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 13 loss 0.37303903698921204\n",
      "tensor(19.1088, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 13 loss 0.05748356506228447\n",
      "tensor(22.9779, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 13 loss 2.105222463607788\n",
      "tensor(17.9552, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 13 loss 0.028366202488541603\n",
      "tensor(18.6266, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 13 loss 0.18678326904773712\n",
      "tensor(14.3893, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 13 loss 0.0031491946429014206\n",
      "tensor(20.4145, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 13 loss 1.9540319442749023\n",
      "tensor(11.5416, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 13 loss 0.05332815274596214\n",
      "tensor(11.2181, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 13 loss 0.027709437534213066\n",
      "tensor(15.9797, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 13 loss 0.0057211462408304214\n",
      "tensor(15.9694, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 13 loss 0.0057715196162462234\n",
      "tensor(19.8869, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 13 loss 0.010528496466577053\n",
      "tensor(21.0244, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 13 loss 0.0025909922551363707\n",
      "tensor(20.0938, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 13 loss 0.20964515209197998\n",
      "tensor(11.3740, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 13 loss 0.04333946108818054\n",
      "tensor(20.1253, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 13 loss 0.02988428995013237\n",
      "tensor(20.2774, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 13 loss 0.2210862636566162\n",
      "tensor(16.5705, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 13 loss 0.04227087274193764\n",
      "tensor(12.7224, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 13 loss 0.12607184052467346\n",
      "tensor(13.3844, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 13 loss 0.0008382858941331506\n",
      "tensor(19.7723, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 13 loss 0.0017819016939029098\n",
      "tensor(23.0790, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 13 loss 0.012184709310531616\n",
      "tensor(16.2792, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 13 loss 0.006355076562613249\n",
      "tensor(14.1770, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 13 loss 0.02063567377626896\n",
      "tensor(17.7328, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 13 loss 0.289241760969162\n",
      "tensor(13.9728, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 13 loss 0.6534014940261841\n",
      "tensor(22.5505, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 13 loss 0.2777993679046631\n",
      "tensor(10.2046, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 13 loss 0.44726675748825073\n",
      "tensor(23.0260, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 13 loss 0.006119206547737122\n",
      "tensor(18.0828, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 13 loss 2.018993616104126\n",
      "tensor(14.9200, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 13 loss 0.00833863578736782\n",
      "tensor(24.2677, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 13 loss 0.7230488657951355\n",
      "tensor(30.4734, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 13 loss 0.2916333079338074\n",
      "tensor(21.6624, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 13 loss 0.07235042750835419\n",
      "tensor(18.7679, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 13 loss 0.25669223070144653\n",
      "tensor(12.1672, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 13 loss 0.026181189343333244\n",
      "tensor(21.1274, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 13 loss 1.6544171571731567\n",
      "tensor(15.4017, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 13 loss 0.20982308685779572\n",
      "tensor(18.3463, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 13 loss 3.0300419330596924\n",
      "tensor(14.6094, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 13 loss 0.013577612116932869\n",
      "tensor(12.4076, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 13 loss 0.4173726439476013\n",
      "tensor(17.0826, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 13 loss 0.7128018140792847\n",
      "tensor(12.2229, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 13 loss 0.05280202627182007\n",
      "tensor(24.7433, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 13 loss 0.2127602994441986\n",
      "tensor(18.1926, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 13 loss 0.023128271102905273\n",
      "tensor(21.4157, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 13 loss 1.7657814025878906\n",
      "tensor(19.3426, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 13 loss 0.1953326165676117\n",
      "tensor(13.4570, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 13 loss 0.07808366417884827\n",
      "tensor(13.4524, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 13 loss 0.0017204972682520747\n",
      "tensor(20.9969, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 13 loss 0.08557800203561783\n",
      "tensor(17.1259, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 13 loss 1.0012197494506836\n",
      "tensor(13.1251, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 13 loss 0.011474094353616238\n",
      "tensor(18.6581, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 13 loss 0.09623029083013535\n",
      "tensor(19.5975, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 13 loss 0.007959670387208462\n",
      "tensor(21.3074, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 13 loss 0.3057578504085541\n",
      "tensor(20.8931, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 13 loss 0.00219533103518188\n",
      "tensor(23.9207, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 14 loss 0.0148306954652071\n",
      "tensor(17.7640, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 14 loss 0.10878673195838928\n",
      "tensor(19.8705, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 14 loss 0.002995767630636692\n",
      "tensor(17.7128, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 14 loss 0.03855815902352333\n",
      "tensor(24.0602, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 14 loss 0.0007233386859297752\n",
      "tensor(23.9394, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 14 loss 1.5702016353607178\n",
      "tensor(21.7854, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 14 loss 0.0029284947086125612\n",
      "tensor(21.4494, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 14 loss 0.011721900664269924\n",
      "tensor(12.7309, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 14 loss 0.001365087111480534\n",
      "tensor(23.9051, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 14 loss 0.005589214153587818\n",
      "tensor(18.5799, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 14 loss 0.10008643567562103\n",
      "tensor(19.4506, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 14 loss 0.3387022614479065\n",
      "tensor(12.3639, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 14 loss 0.3849981725215912\n",
      "tensor(14.0658, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 14 loss 0.013213332742452621\n",
      "tensor(26.2006, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 14 loss 0.057887423783540726\n",
      "tensor(24.5782, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 14 loss 0.029603563249111176\n",
      "tensor(17.1720, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 14 loss 0.003968697972595692\n",
      "tensor(19.2257, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 14 loss 0.036123666912317276\n",
      "tensor(12.3976, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 14 loss 0.019250471144914627\n",
      "tensor(13.8554, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 14 loss 0.3125970959663391\n",
      "tensor(13.3456, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 14 loss 0.06674426794052124\n",
      "tensor(17.9324, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 14 loss 3.812221050262451\n",
      "tensor(20.8660, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 14 loss 0.15699759125709534\n",
      "tensor(14.2265, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 14 loss 0.35584625601768494\n",
      "tensor(13.5387, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 14 loss 0.06621332466602325\n",
      "tensor(16.6102, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 14 loss 0.005779698025435209\n",
      "tensor(20.9273, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 14 loss 1.6163339614868164\n",
      "tensor(26.1611, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 14 loss 0.22593002021312714\n",
      "tensor(13.1410, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 14 loss 0.011971413157880306\n",
      "tensor(24.5826, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 14 loss 0.14691197872161865\n",
      "tensor(23.6077, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 14 loss 0.08698561787605286\n",
      "tensor(13.9282, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 14 loss 0.15559452772140503\n",
      "tensor(19.5151, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 14 loss 0.08063073456287384\n",
      "tensor(25.6308, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 14 loss 0.015543858520686626\n",
      "tensor(25.8905, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 14 loss 0.03575658053159714\n",
      "tensor(20.0893, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 14 loss 3.032529830932617\n",
      "tensor(19.9295, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 14 loss 0.3374383747577667\n",
      "tensor(13.4658, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 14 loss 0.1678236722946167\n",
      "tensor(13.2162, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 14 loss 0.13626110553741455\n",
      "tensor(14.0747, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 14 loss 1.2199467420578003\n",
      "tensor(12.6579, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 14 loss 0.346840500831604\n",
      "tensor(18.5993, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 14 loss 0.09000150859355927\n",
      "tensor(13.4343, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 14 loss 0.08975809067487717\n",
      "tensor(25.8950, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 14 loss 0.05335640534758568\n",
      "tensor(17.6130, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 14 loss 0.6612538695335388\n",
      "tensor(19.4713, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 14 loss 0.16969513893127441\n",
      "tensor(14.8242, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 14 loss 0.007849915884435177\n",
      "tensor(19.4328, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 14 loss 0.08662110567092896\n",
      "tensor(15.0113, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 14 loss 1.9543683528900146\n",
      "tensor(17.9792, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 14 loss 0.027305729687213898\n",
      "tensor(12.7808, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 14 loss 0.09342415630817413\n",
      "tensor(12.8080, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 14 loss 0.013531393371522427\n",
      "tensor(13.7972, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 14 loss 0.12291228026151657\n",
      "tensor(14.5820, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 14 loss 0.25899162888526917\n",
      "tensor(12.0466, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 14 loss 0.5045482516288757\n",
      "tensor(17.9394, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 14 loss 1.480363368988037\n",
      "tensor(15.1121, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 14 loss 0.012163746170699596\n",
      "tensor(24.9306, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 14 loss 0.2803202271461487\n",
      "tensor(11.4340, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 14 loss 0.00943818036466837\n",
      "tensor(20.6542, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 14 loss 0.09060055017471313\n",
      "tensor(17.3494, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 15 loss 0.11489070951938629\n",
      "tensor(24.1230, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 15 loss 0.015550313517451286\n",
      "tensor(18.2307, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 15 loss 0.2532181441783905\n",
      "tensor(17.8503, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 15 loss 0.015135208144783974\n",
      "tensor(14.5168, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 15 loss 0.2514086067676544\n",
      "tensor(12.5712, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 15 loss 0.013573378324508667\n",
      "tensor(24.9589, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 15 loss 2.2372217178344727\n",
      "tensor(22.9171, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 15 loss 0.28537702560424805\n",
      "tensor(12.5299, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 15 loss 1.202354073524475\n",
      "tensor(10.4811, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 15 loss 0.08366274833679199\n",
      "tensor(14.5594, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 15 loss 0.013005080632865429\n",
      "tensor(13.5325, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 15 loss 0.28981664776802063\n",
      "tensor(11.6810, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 15 loss 0.49512508511543274\n",
      "tensor(14.3836, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 15 loss 0.09092322736978531\n",
      "tensor(13.2525, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 15 loss 0.05466720461845398\n",
      "tensor(21.0423, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 15 loss 0.023983711376786232\n",
      "tensor(21.0094, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 15 loss 0.14184829592704773\n",
      "tensor(15.4599, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 15 loss 0.013224979862570763\n",
      "tensor(15.4140, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 15 loss 0.00928488839417696\n",
      "tensor(13.2953, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 15 loss 0.0036618339363485575\n",
      "tensor(22.3708, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 15 loss 0.01247719582170248\n",
      "tensor(12.7925, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 15 loss 0.048395175486803055\n",
      "tensor(23.0728, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 15 loss 0.07275885343551636\n",
      "tensor(17.4961, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 15 loss 0.012607044540345669\n",
      "tensor(16.3423, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 15 loss 0.0006876011611893773\n",
      "tensor(23.1259, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 15 loss 0.3759816586971283\n",
      "tensor(17.1422, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 15 loss 0.21791070699691772\n",
      "tensor(10.9106, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 15 loss 0.004185013473033905\n",
      "tensor(22.0863, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 15 loss 0.190669447183609\n",
      "tensor(14.7411, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 15 loss 0.7249345183372498\n",
      "tensor(15.5414, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 15 loss 0.0038417596369981766\n",
      "tensor(23.9675, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 15 loss 0.47152382135391235\n",
      "tensor(22.9684, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 15 loss 1.9425121545791626\n",
      "tensor(20.8125, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 15 loss 0.0033721032086759806\n",
      "tensor(23.0324, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 15 loss 0.5416843891143799\n",
      "tensor(20.6860, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 15 loss 0.00047946401173248887\n",
      "tensor(25.3982, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 15 loss 0.4648299515247345\n",
      "tensor(18.5118, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 15 loss 0.7356302738189697\n",
      "tensor(12.1139, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 15 loss 2.3576738834381104\n",
      "tensor(20.6497, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 15 loss 0.018132636323571205\n",
      "tensor(17.8225, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 15 loss 0.27671462297439575\n",
      "tensor(15.5008, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 15 loss 0.0023384150117635727\n",
      "tensor(21.2312, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 15 loss 0.055772241204977036\n",
      "tensor(20.4517, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 15 loss 0.09841705858707428\n",
      "tensor(14.5975, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 15 loss 0.007833002135157585\n",
      "tensor(22.8821, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 15 loss 0.22630588710308075\n",
      "tensor(18.0131, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 15 loss 0.004417423624545336\n",
      "tensor(27.4030, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 15 loss 0.014318462461233139\n",
      "tensor(17.8834, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 15 loss 0.025336693972349167\n",
      "tensor(17.9568, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 15 loss 0.18959437310695648\n",
      "tensor(18.6606, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 15 loss 0.44323503971099854\n",
      "tensor(19.3648, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 15 loss 0.014323398470878601\n",
      "tensor(21.5453, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 15 loss 0.5420406460762024\n",
      "tensor(14.9820, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 15 loss 0.0027583905030041933\n",
      "tensor(20.4835, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 15 loss 0.010302693583071232\n",
      "tensor(19.6879, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 15 loss 0.1986784040927887\n",
      "tensor(13.9428, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 15 loss 0.07257838547229767\n",
      "tensor(17.3525, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 15 loss 1.8801298141479492\n",
      "tensor(26.4317, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 15 loss 0.024157226085662842\n",
      "tensor(27.2173, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 15 loss 0.23285821080207825\n",
      "tensor(18.6055, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 16 loss 0.5951282382011414\n",
      "tensor(21.6004, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 16 loss 0.8638638854026794\n",
      "tensor(10.6714, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 16 loss 0.7269294857978821\n",
      "tensor(16.2915, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 16 loss 0.42286163568496704\n",
      "tensor(23.9256, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 16 loss 0.37755972146987915\n",
      "tensor(11.2556, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 16 loss 0.11942380666732788\n",
      "tensor(20.3206, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 16 loss 0.0032296422868967056\n",
      "tensor(23.7751, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 16 loss 0.026767931878566742\n",
      "tensor(21.2366, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 16 loss 1.6531033515930176\n",
      "tensor(15.0463, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 16 loss 0.012518518604338169\n",
      "tensor(20.1340, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 16 loss 0.015216927975416183\n",
      "tensor(17.3057, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 16 loss 0.13190029561519623\n",
      "tensor(24.4060, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 16 loss 0.03272910788655281\n",
      "tensor(19.3269, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 16 loss 0.17651736736297607\n",
      "tensor(13.2564, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 16 loss 0.11490165442228317\n",
      "tensor(21.5717, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 16 loss 0.41035833954811096\n",
      "tensor(14.6586, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 16 loss 0.013521749526262283\n",
      "tensor(14.8720, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 16 loss 0.015467681922018528\n",
      "tensor(17.5833, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 16 loss 1.683190941810608\n",
      "tensor(14.9949, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 16 loss 0.009798642247915268\n",
      "tensor(15.9999, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 16 loss 0.042085159569978714\n",
      "tensor(17.0296, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 16 loss 1.6567367315292358\n",
      "tensor(17.4289, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 16 loss 0.04427473619580269\n",
      "tensor(15.2961, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 16 loss 0.2816743552684784\n",
      "tensor(17.1347, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 16 loss 0.33131104707717896\n",
      "tensor(14.6647, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 16 loss 0.5314804911613464\n",
      "tensor(12.5193, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 16 loss 0.0020394970197230577\n",
      "tensor(27.4074, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 16 loss 0.9403014183044434\n",
      "tensor(22.2668, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 16 loss 0.017333684489130974\n",
      "tensor(18.2264, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 16 loss 0.011427778750658035\n",
      "tensor(14.5262, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 16 loss 0.018860995769500732\n",
      "tensor(19.5530, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 16 loss 0.3006044626235962\n",
      "tensor(12.1897, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 16 loss 0.10341256111860275\n",
      "tensor(24.5222, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 16 loss 0.9210073947906494\n",
      "tensor(18.7221, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 16 loss 1.2187036275863647\n",
      "tensor(16.4682, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 16 loss 0.002436052542179823\n",
      "tensor(28.5077, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 16 loss 0.3854061961174011\n",
      "tensor(28.2662, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 16 loss 0.45872506499290466\n",
      "tensor(19.0664, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 16 loss 0.20745216310024261\n",
      "tensor(15.6075, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 16 loss 0.1352178305387497\n",
      "tensor(23.9455, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 16 loss 0.008736246265470982\n",
      "tensor(24.5220, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 16 loss 0.0691336840391159\n",
      "tensor(21.9133, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 16 loss 0.008271366357803345\n",
      "tensor(25.9090, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 16 loss 0.08309848606586456\n",
      "tensor(15.9938, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 16 loss 0.010375135578215122\n",
      "tensor(16.0094, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 16 loss 0.0383458249270916\n",
      "tensor(15.2239, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 16 loss 0.0952424630522728\n",
      "tensor(19.3098, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 16 loss 0.009760159067809582\n",
      "tensor(21.4965, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 16 loss 0.31245389580726624\n",
      "tensor(25.1921, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 16 loss 0.015970760956406593\n",
      "tensor(24.5343, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 16 loss 0.00856842752546072\n",
      "tensor(31.3836, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 16 loss 1.1621508598327637\n",
      "tensor(20.5103, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 16 loss 0.11640062928199768\n",
      "tensor(13.3246, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 16 loss 0.03337209299206734\n",
      "tensor(24.4123, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 16 loss 0.8745779395103455\n",
      "tensor(24.8728, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 16 loss 0.00946439616382122\n",
      "tensor(15.4931, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 16 loss 0.722916841506958\n",
      "tensor(16.4882, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 16 loss 0.7237741351127625\n",
      "tensor(16.5933, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 16 loss 0.039334721863269806\n",
      "tensor(20.0127, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 16 loss 0.024497531354427338\n",
      "tensor(14.2812, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 17 loss 0.11535447090864182\n",
      "tensor(25.6352, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 17 loss 1.0023359060287476\n",
      "tensor(16.1153, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 17 loss 0.22354230284690857\n",
      "tensor(15.0325, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 17 loss 0.009812572039663792\n",
      "tensor(20.5144, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 17 loss 0.6839181184768677\n",
      "tensor(10.5214, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 17 loss 0.005287472158670425\n",
      "tensor(28.0352, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 17 loss 0.003924882970750332\n",
      "tensor(23.5193, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 17 loss 1.3095335960388184\n",
      "tensor(24.2284, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 17 loss 0.0036336842458695173\n",
      "tensor(20.1185, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 17 loss 0.15065644681453705\n",
      "tensor(22.0681, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 17 loss 0.8682812452316284\n",
      "tensor(11.0750, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 17 loss 0.0756118893623352\n",
      "tensor(29.3764, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 17 loss 0.858934223651886\n",
      "tensor(18.4882, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 17 loss 0.05779629200696945\n",
      "tensor(18.0908, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 17 loss 0.029466411098837852\n",
      "tensor(14.4414, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 17 loss 0.001192930736579001\n",
      "tensor(27.6716, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 17 loss 0.36856916546821594\n",
      "tensor(21.4258, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 17 loss 0.29930126667022705\n",
      "tensor(15.7513, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 17 loss 0.04422729089856148\n",
      "tensor(29.2876, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 17 loss 0.019940508529543877\n",
      "tensor(17.2473, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 17 loss 0.616708517074585\n",
      "tensor(20.9880, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 17 loss 0.24630995094776154\n",
      "tensor(21.9689, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 17 loss 0.014579428359866142\n",
      "tensor(23.0758, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 17 loss 0.681941568851471\n",
      "tensor(25.8159, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 17 loss 0.033522315323352814\n",
      "tensor(14.9945, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 17 loss 0.18401779234409332\n",
      "tensor(23.2723, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 17 loss 0.17499543726444244\n",
      "tensor(11.7349, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 17 loss 0.006409327033907175\n",
      "tensor(22.1442, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 17 loss 0.36715176701545715\n",
      "tensor(16.2225, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 17 loss 0.4303680658340454\n",
      "tensor(17.3483, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 17 loss 0.4884662926197052\n",
      "tensor(16.5620, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 17 loss 0.004318673629313707\n",
      "tensor(18.3271, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 17 loss 0.4536330997943878\n",
      "tensor(11.0535, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 17 loss 0.00541126262396574\n",
      "tensor(21.2684, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 17 loss 0.01742612011730671\n",
      "tensor(18.2593, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 17 loss 0.027609597891569138\n",
      "tensor(21.0529, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 17 loss 0.05168532207608223\n",
      "tensor(25.4131, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 17 loss 0.04746260866522789\n",
      "tensor(22.1806, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 17 loss 0.02367757447063923\n",
      "tensor(16.2036, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 17 loss 0.17041872441768646\n",
      "tensor(21.5284, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 17 loss 0.013042381033301353\n",
      "tensor(20.2762, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 17 loss 0.8859043121337891\n",
      "tensor(19.3072, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 17 loss 0.01490821223706007\n",
      "tensor(24.8253, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 17 loss 0.22148928046226501\n",
      "tensor(19.6424, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 17 loss 0.0072442712262272835\n",
      "tensor(20.4586, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 17 loss 0.001955384388566017\n",
      "tensor(24.8061, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 17 loss 0.044595953077077866\n",
      "tensor(24.5839, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 17 loss 0.0072745680809021\n",
      "tensor(15.2951, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 17 loss 0.28547579050064087\n",
      "tensor(20.2060, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 17 loss 0.1862860769033432\n",
      "tensor(21.4199, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 17 loss 0.058020059019327164\n",
      "tensor(28.5140, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 17 loss 2.5330381393432617\n",
      "tensor(21.3821, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 17 loss 0.5005343556404114\n",
      "tensor(20.0683, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 17 loss 0.001666824915446341\n",
      "tensor(22.5601, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 17 loss 0.02543606236577034\n",
      "tensor(11.0968, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 17 loss 0.1426154524087906\n",
      "tensor(23.9898, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 17 loss 0.003364499658346176\n",
      "tensor(28.5234, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 17 loss 0.015416385605931282\n",
      "tensor(26.9715, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 17 loss 0.0029950544703751802\n",
      "tensor(28.1673, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 17 loss 0.014952017925679684\n",
      "tensor(30.8264, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 18 loss 1.2648446559906006\n",
      "tensor(23.0426, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 18 loss 0.0050840857438743114\n",
      "tensor(20.6272, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 18 loss 0.22842010855674744\n",
      "tensor(21.4881, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 18 loss 0.5173152685165405\n",
      "tensor(21.1258, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 18 loss 0.008958149701356888\n",
      "tensor(23.8855, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 18 loss 0.1465887427330017\n",
      "tensor(22.4477, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 18 loss 0.04153421148657799\n",
      "tensor(14.2903, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 18 loss 0.13975808024406433\n",
      "tensor(16.2067, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 18 loss 0.010756370611488819\n",
      "tensor(27.1987, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 18 loss 0.2076568305492401\n",
      "tensor(17.7329, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 18 loss 0.527168869972229\n",
      "tensor(20.5115, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 18 loss 0.07810825109481812\n",
      "tensor(14.0575, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 18 loss 0.022368507459759712\n",
      "tensor(20.3187, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 18 loss 0.026031488552689552\n",
      "tensor(25.6737, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 18 loss 0.013149449601769447\n",
      "tensor(16.7895, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 18 loss 0.8471090793609619\n",
      "tensor(23.6963, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 18 loss 0.025282762944698334\n",
      "tensor(16.8434, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 18 loss 1.0003061294555664\n",
      "tensor(19.5895, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 18 loss 0.0932186022400856\n",
      "tensor(20.7319, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 18 loss 0.16066832840442657\n",
      "tensor(13.4406, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 18 loss 0.04918865114450455\n",
      "tensor(28.9720, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 18 loss 0.06266631931066513\n",
      "tensor(17.2863, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 18 loss 2.410642385482788\n",
      "tensor(18.8194, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 18 loss 0.22632956504821777\n",
      "tensor(14.6823, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 18 loss 0.09341786056756973\n",
      "tensor(23.0864, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 18 loss 0.11509759724140167\n",
      "tensor(16.8718, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 18 loss 0.010024086572229862\n",
      "tensor(13.3555, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 18 loss 0.0053669181652367115\n",
      "tensor(27.5312, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 18 loss 2.2560603618621826\n",
      "tensor(22.3272, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 18 loss 0.001774523756466806\n",
      "tensor(25.5719, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 18 loss 0.022641366347670555\n",
      "tensor(25.5034, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 18 loss 0.16316847503185272\n",
      "tensor(14.4373, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 18 loss 0.008681177161633968\n",
      "tensor(20.4992, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 18 loss 0.003521077334880829\n",
      "tensor(26.0072, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 18 loss 1.5450705289840698\n",
      "tensor(19.0660, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 18 loss 0.20898181200027466\n",
      "tensor(18.2687, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 18 loss 0.15961983799934387\n",
      "tensor(12.7034, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 18 loss 0.04549838975071907\n",
      "tensor(15.8524, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 18 loss 0.009853060357272625\n",
      "tensor(21.1533, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 18 loss 0.0028855851851403713\n",
      "tensor(27.0394, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 18 loss 0.009328587912023067\n",
      "tensor(17.5200, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 18 loss 0.38423702120780945\n",
      "tensor(13.9784, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 18 loss 0.01032180804759264\n",
      "tensor(17.1161, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 18 loss 0.1599031239748001\n",
      "tensor(17.6204, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 18 loss 0.2299717664718628\n",
      "tensor(13.4280, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 18 loss 0.0029444219544529915\n",
      "tensor(25.7211, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 18 loss 0.08293051272630692\n",
      "tensor(19.2334, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 18 loss 0.25388431549072266\n",
      "tensor(23.9310, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 18 loss 0.41821062564849854\n",
      "tensor(21.3435, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 18 loss 0.003975228406488895\n",
      "tensor(26.6846, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 18 loss 0.005584472790360451\n",
      "tensor(27.1788, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 18 loss 0.027598928660154343\n",
      "tensor(15.2752, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 18 loss 0.026663588359951973\n",
      "tensor(29.1330, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 18 loss 0.023914692923426628\n",
      "tensor(22.9540, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 18 loss 0.015106556937098503\n",
      "tensor(26.1806, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 18 loss 0.0801977813243866\n",
      "tensor(11.3736, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 18 loss 0.3611925542354584\n",
      "tensor(9.9269, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 18 loss 0.078067347407341\n",
      "tensor(25.3226, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 18 loss 0.017906084656715393\n",
      "tensor(21.3424, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 18 loss 0.011775507591664791\n",
      "tensor(19.5326, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "99\n",
      "epoch 19 loss 0.0637635588645935\n",
      "tensor(19.7193, grad_fn=<AddBackward0>)\n",
      "199\n",
      "epoch 19 loss 0.21977101266384125\n",
      "tensor(23.4670, grad_fn=<AddBackward0>)\n",
      "299\n",
      "epoch 19 loss 0.06941854953765869\n",
      "tensor(22.6185, grad_fn=<AddBackward0>)\n",
      "399\n",
      "epoch 19 loss 0.22852739691734314\n",
      "tensor(12.2631, grad_fn=<AddBackward0>)\n",
      "499\n",
      "epoch 19 loss 0.10257609933614731\n",
      "tensor(11.7353, grad_fn=<AddBackward0>)\n",
      "599\n",
      "epoch 19 loss 0.10062826424837112\n",
      "tensor(17.9854, grad_fn=<AddBackward0>)\n",
      "699\n",
      "epoch 19 loss 0.21100002527236938\n",
      "tensor(17.0747, grad_fn=<AddBackward0>)\n",
      "799\n",
      "epoch 19 loss 0.012067525647580624\n",
      "tensor(27.0273, grad_fn=<AddBackward0>)\n",
      "899\n",
      "epoch 19 loss 0.0556485541164875\n",
      "tensor(31.2937, grad_fn=<AddBackward0>)\n",
      "999\n",
      "epoch 19 loss 0.024116963148117065\n",
      "tensor(23.5434, grad_fn=<AddBackward0>)\n",
      "1099\n",
      "epoch 19 loss 0.0188105758279562\n",
      "tensor(22.4720, grad_fn=<AddBackward0>)\n",
      "1199\n",
      "epoch 19 loss 0.4783201813697815\n",
      "tensor(21.3677, grad_fn=<AddBackward0>)\n",
      "1299\n",
      "epoch 19 loss 0.20320279896259308\n",
      "tensor(14.3863, grad_fn=<AddBackward0>)\n",
      "1399\n",
      "epoch 19 loss 0.01596383936703205\n",
      "tensor(17.4074, grad_fn=<AddBackward0>)\n",
      "1499\n",
      "epoch 19 loss 0.26243290305137634\n",
      "tensor(17.8752, grad_fn=<AddBackward0>)\n",
      "1599\n",
      "epoch 19 loss 0.026654185727238655\n",
      "tensor(17.6141, grad_fn=<AddBackward0>)\n",
      "1699\n",
      "epoch 19 loss 0.11630140990018845\n",
      "tensor(22.9250, grad_fn=<AddBackward0>)\n",
      "1799\n",
      "epoch 19 loss 0.36374521255493164\n",
      "tensor(18.0311, grad_fn=<AddBackward0>)\n",
      "1899\n",
      "epoch 19 loss 0.039929721504449844\n",
      "tensor(29.3733, grad_fn=<AddBackward0>)\n",
      "1999\n",
      "epoch 19 loss 0.06994223594665527\n",
      "tensor(15.6170, grad_fn=<AddBackward0>)\n",
      "2099\n",
      "epoch 19 loss 0.0675559714436531\n",
      "tensor(14.8211, grad_fn=<AddBackward0>)\n",
      "2199\n",
      "epoch 19 loss 0.0787530243396759\n",
      "tensor(13.8079, grad_fn=<AddBackward0>)\n",
      "2299\n",
      "epoch 19 loss 0.5447361469268799\n",
      "tensor(12.1409, grad_fn=<AddBackward0>)\n",
      "2399\n",
      "epoch 19 loss 0.5618714094161987\n",
      "tensor(23.3411, grad_fn=<AddBackward0>)\n",
      "2499\n",
      "epoch 19 loss 0.004162457771599293\n",
      "tensor(23.2538, grad_fn=<AddBackward0>)\n",
      "2599\n",
      "epoch 19 loss 1.0422441959381104\n",
      "tensor(13.7033, grad_fn=<AddBackward0>)\n",
      "2699\n",
      "epoch 19 loss 0.25012627243995667\n",
      "tensor(16.3795, grad_fn=<AddBackward0>)\n",
      "2799\n",
      "epoch 19 loss 0.02856270782649517\n",
      "tensor(13.5739, grad_fn=<AddBackward0>)\n",
      "2899\n",
      "epoch 19 loss 0.015451952815055847\n",
      "tensor(18.8345, grad_fn=<AddBackward0>)\n",
      "2999\n",
      "epoch 19 loss 0.012393131852149963\n",
      "tensor(25.9163, grad_fn=<AddBackward0>)\n",
      "3099\n",
      "epoch 19 loss 0.014248421415686607\n",
      "tensor(14.0127, grad_fn=<AddBackward0>)\n",
      "3199\n",
      "epoch 19 loss 0.04424189031124115\n",
      "tensor(30.1579, grad_fn=<AddBackward0>)\n",
      "3299\n",
      "epoch 19 loss 0.18379701673984528\n",
      "tensor(26.0546, grad_fn=<AddBackward0>)\n",
      "3399\n",
      "epoch 19 loss 1.1540428400039673\n",
      "tensor(24.7519, grad_fn=<AddBackward0>)\n",
      "3499\n",
      "epoch 19 loss 0.14182429015636444\n",
      "tensor(19.7646, grad_fn=<AddBackward0>)\n",
      "3599\n",
      "epoch 19 loss 0.023508984595537186\n",
      "tensor(11.3104, grad_fn=<AddBackward0>)\n",
      "3699\n",
      "epoch 19 loss 2.5690245628356934\n",
      "tensor(21.7108, grad_fn=<AddBackward0>)\n",
      "3799\n",
      "epoch 19 loss 0.0014148473273962736\n",
      "tensor(27.0971, grad_fn=<AddBackward0>)\n",
      "3899\n",
      "epoch 19 loss 0.0036501940339803696\n",
      "tensor(22.6835, grad_fn=<AddBackward0>)\n",
      "3999\n",
      "epoch 19 loss 1.7663458585739136\n",
      "tensor(20.6517, grad_fn=<AddBackward0>)\n",
      "4099\n",
      "epoch 19 loss 0.12769058346748352\n",
      "tensor(15.2599, grad_fn=<AddBackward0>)\n",
      "4199\n",
      "epoch 19 loss 0.03859681263566017\n",
      "tensor(13.7042, grad_fn=<AddBackward0>)\n",
      "4299\n",
      "epoch 19 loss 0.9495724439620972\n",
      "tensor(23.2767, grad_fn=<AddBackward0>)\n",
      "4399\n",
      "epoch 19 loss 0.3297978639602661\n",
      "tensor(12.6913, grad_fn=<AddBackward0>)\n",
      "4499\n",
      "epoch 19 loss 0.002856343751773238\n",
      "tensor(22.8518, grad_fn=<AddBackward0>)\n",
      "4599\n",
      "epoch 19 loss 0.03780291602015495\n",
      "tensor(14.4337, grad_fn=<AddBackward0>)\n",
      "4699\n",
      "epoch 19 loss 0.962410032749176\n",
      "tensor(19.5143, grad_fn=<AddBackward0>)\n",
      "4799\n",
      "epoch 19 loss 0.003909802529960871\n",
      "tensor(22.1968, grad_fn=<AddBackward0>)\n",
      "4899\n",
      "epoch 19 loss 0.0046491860412061214\n",
      "tensor(18.2051, grad_fn=<AddBackward0>)\n",
      "4999\n",
      "epoch 19 loss 0.04109508916735649\n",
      "tensor(17.6759, grad_fn=<AddBackward0>)\n",
      "5099\n",
      "epoch 19 loss 0.22845691442489624\n",
      "tensor(25.0305, grad_fn=<AddBackward0>)\n",
      "5199\n",
      "epoch 19 loss 0.1800958663225174\n",
      "tensor(15.2946, grad_fn=<AddBackward0>)\n",
      "5299\n",
      "epoch 19 loss 0.17041942477226257\n",
      "tensor(17.1295, grad_fn=<AddBackward0>)\n",
      "5399\n",
      "epoch 19 loss 0.24932046234607697\n",
      "tensor(24.3698, grad_fn=<AddBackward0>)\n",
      "5499\n",
      "epoch 19 loss 0.4885093569755554\n",
      "tensor(23.5716, grad_fn=<AddBackward0>)\n",
      "5599\n",
      "epoch 19 loss 0.014552054926753044\n",
      "tensor(26.7572, grad_fn=<AddBackward0>)\n",
      "5699\n",
      "epoch 19 loss 0.11089406907558441\n",
      "tensor(19.0993, grad_fn=<AddBackward0>)\n",
      "5799\n",
      "epoch 19 loss 0.0013778250431641936\n",
      "tensor(23.4212, grad_fn=<AddBackward0>)\n",
      "5899\n",
      "epoch 19 loss 0.07633702456951141\n",
      "tensor(22.4936, grad_fn=<AddBackward0>)\n",
      "5999\n",
      "epoch 19 loss 0.08292414993047714\n",
      "tensor(26.4350, grad_fn=<AddBackward0>)\n",
      "check pointing\n",
      "finished training loss 0.08292414993047714\n"
     ]
    }
   ],
   "source": [
    "reward_net = Net(8)\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(reward_net.parameters(),  lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "reward_model_path = 'reward_model/model0.pth'\n",
    "\n",
    "learn_reward(reward_net, optimizer, training_obs, training_labels, num_iter, l1_reg, reward_model_path) #path is where to save the model\n",
    "#save reward network\n",
    "torch.save(reward_net.state_dict(), reward_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st see how it learns reward \"Network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 54.4447066783905 -362.18852614808526\n",
      "1 47.720975428819656 -217.61016424414632\n",
      "2 52.097526013851166 -189.99518832828852\n",
      "3 42.32231566309929 -159.36152768835598\n",
      "4 29.00987595319748 -146.1140926064082\n",
      "5 35.61240200698376 -137.5032035750756\n",
      "6 34.20258581638336 -135.85084168721104\n",
      "7 24.991241216659546 -110.27148638803381\n",
      "8 66.75667610764503 -106.96702195811058\n",
      "9 51.61147516965866 -94.48181129665147\n",
      "10 34.576077088713646 -90.10019050638121\n",
      "11 27.2677384018898 -89.50723549407869\n",
      "12 27.17969697713852 -89.31660912002741\n",
      "13 38.593479454517365 -88.17919788862693\n",
      "14 21.600657999515533 -57.02610638521248\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        pred_returns = [predict_traj_return(reward_net, traj[0]) for traj in sorted_demonstrations]\n",
    "for i, p in enumerate(pred_returns):\n",
    "    print(i,p,sorted_rewards[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2d5ad69a550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pred_returns, sorted_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_names = ['1668059133.6913733', '1668059364.6035125', '1668059396.1789556', '1668059459.6041403', '1668091394.3350058', '1668091478.0278926']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_path = 'data/demonstrations/gym-'\n",
    "# demos = [pickle.load(open(demo_path+ f'{demo_name}' + '.pickle', 'rb'), encoding='latin1') for demo_name in demo_names] # load from files\n",
    "# demos[demo #] = control, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = TerminalHuman(env, 'approx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = H.input(demos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc672",
   "language": "python",
   "name": "cpsc672"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d49e151782fed93a6f134ef8d54ea6efc441a9808d334581963f6e1390574c3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
